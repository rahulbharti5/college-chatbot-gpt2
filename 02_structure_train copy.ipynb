{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run this code if you are in google colab\n",
    "# !git clone https://github.com/rahulbharti5/college-chatbot-gpt2 .\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imporinting All Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulbharti/Preojects/college-chatbot-gpt2/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import nltk\n",
    "from glob import glob\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "from chatbot_files.data import Dialogues\n",
    "from chatbot_files.utils import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Downloading the NLTK Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/rahulbharti/Preojects/college-chatbot-\n",
      "[nltk_data]     gpt2/venv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/rahulbharti/Preojects/college-chatbot-\n",
      "[nltk_data]     gpt2/venv/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/rahulbharti/Preojects/college-chatbot-\n",
      "[nltk_data]     gpt2/venv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/rahulbharti/Preojects/college-chatbot-\n",
      "[nltk_data]     gpt2/venv/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Opening The Model Configuration\n",
    "and Setting Seeds Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'structure_dataset_dir': './process_data/structred_data',\n",
       " 'corpus_dataset_dir': './process_data/corpus_data',\n",
       " 'train_frac': 0.85,\n",
       " 'model_name': 'gpt2',\n",
       " 'seed': 8459,\n",
       " 'lr': 2e-05,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'batch_size': 1,\n",
       " 'num_epochs': 10,\n",
       " 'max_len': 100,\n",
       " 'max_history': 5,\n",
       " 'models_dir': './models',\n",
       " 'stop_command': 'bye',\n",
       " 'top_p': 0.9,\n",
       " 'top_k': 50,\n",
       " 'temperature': 0.9,\n",
       " 'mode': 'train',\n",
       " 'checkpoint': 'None',\n",
       " 'model_dir': './models'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make Sure the seed is imported\n",
    "# from utils import set_seed\n",
    "\n",
    "args = yaml.safe_load(open('config.yml'))\n",
    "set_seed(args['seed']) \n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Opening Loading the Model With GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(args):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(args['model_name'])\n",
    "    special_tokens = ['<speaker1>', '<speaker2>']\n",
    "    tokenizer.add_special_tokens({\n",
    "        'bos_token': '<bos>',\n",
    "        'additional_special_tokens': special_tokens\n",
    "    })\n",
    "\n",
    "    # add new token ids to args\n",
    "    special_tokens += ['<bos>', '<eos>']\n",
    "    sp1_id, sp2_id, bos_id, eos_id = tokenizer.encode(special_tokens)\n",
    "    args['sp1_id'] = sp1_id\n",
    "    args['sp2_id'] = sp2_id\n",
    "    args['bos_id'] = bos_id\n",
    "    args['eos_id'] = eos_id\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args, tokenizer, device):\n",
    "    model = GPT2LMHeadModel.from_pretrained(args[\"model_name\"]).to(device)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Loding Model and Tokenizeer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Using device: cpu\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args['device'] = device\n",
    "\n",
    "print(\"--\"*50)\n",
    "print(f'Using device: {device}')\n",
    "print(\"--\"*50)\n",
    "\n",
    "tokenizer = load_tokenizer(args)\n",
    "model = load_model(args, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_files.processing import Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = Processing(tokenizer, args['train_frac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13118/13118 [00:10<00:00, 1297.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train,validation = processing._load_daily()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Say, Jim, How about going for a few beers after dinner?',\n",
       "  'You know that is tempting but is really not good for our fitness.',\n",
       "  'What do you mean? It will help us to relax.',\n",
       "  \"Do you really think so? I don't. It will just make us fat and act silly. Remember last time?\",\n",
       "  \"I guess you are right. But what shall we do? I don't feel like sitting at home.\",\n",
       "  'I suggest a walk over to the gym where we can play singsong and meet some of our friends.',\n",
       "  \"That's a good idea. I hear Mary and Sally often go there to play pingpong. Perhaps we can make a foursome with them.\",\n",
       "  'Sounds great to me! If they are willing, We could ask them to go dancing with us. That is excellent exercise and fun, Too.',\n",
       "  \"Good. Let's go now.\",\n",
       "  'All right.'],\n",
       " ['Can you do push-ups?',\n",
       "  \"Of course I can. It's a piece of cake! Believe it or not, I can do 30 push-ups a minute.\",\n",
       "  \"Really? I think that's impossible!\",\n",
       "  'You mean 30 push-ups?',\n",
       "  'Yeah!',\n",
       "  \"It's easy. If you do exercise everyday, You can make it, Too.\"],\n",
       " ['Can you study with the radio on?',\n",
       "  'No, I listen to background music.',\n",
       "  'What is the difference?',\n",
       "  'The radio has too many comerials.',\n",
       "  \"That's true, But then you have to buy a record player.\"],\n",
       " ['Are you all right?',\n",
       "  'I will be all right soon. I was terrified when I watched them fall from the wire.',\n",
       "  \"Don't worry. He is an acrobat。.\",\n",
       "  'I see.'],\n",
       " ['Hey John, Nice skates. Are they new?',\n",
       "  'Yeah, I just got them. I started playing ice hockey in a community league. So, I finally got myself new skates.',\n",
       "  'What position do you play?',\n",
       "  \"I'm a defender. It's a lot of fun. You don't have to be able to skate as fast on defense.\",\n",
       "  \"Yeah, You're a pretty big guy. I play goalie, Myself.\",\n",
       "  'Oh, Yeah? Which team?',\n",
       "  'The Rockets.',\n",
       "  'Really? I think we play you guys next week. Well, I have to go to practice. See you later.',\n",
       "  'All right, See you later.'],\n",
       " ['Hey Lydia, What are you reading?',\n",
       "  \"I'm looking at my horoscope for this month! My outlook is very positive. It says that I should take a vacation to someplace exotic, And that I will have a passionate summer fling!\",\n",
       "  'What are you talking about? Let me see that... What are horoscopes?',\n",
       "  \"It's a prediction of your month, Based on your zodiac sign. You have a different sign for the month and date you were born in. I was born on April 15th, So I'm an Aries. When were you born?\",\n",
       "  'January 5th.',\n",
       "  \"Let's see... You're a Capricorn. It says that you will be feeling stress at work, But you could see new, Exciting developments in your love life. Looks like we'll both have interesting summers!\",\n",
       "  \"That's bogus. I don't feel any stress at work, And my love life is practically nonexistent. This zodiac stuff is all a bunch of nonsense.\",\n",
       "  \"No, It's not, Your astrology sign can tell you a lot about your personality. See? It says that an Aries is energetic and loves to socialize.\",\n",
       "  \"Well, You certainly match those criteria, But they're so broad they could apply to anyone. What does it say about me?\",\n",
       "  'A Capricorn is serious-minded and practical. She likes to do things in conventional ways. That sounds just like you!'],\n",
       " [\"Frank's getting married, Do you believe this?\",\n",
       "  'Is he really?',\n",
       "  'Yes, He is. He loves the girl very much.',\n",
       "  'Who is he marring?',\n",
       "  'A girl he met on holiday in Spain, I think.',\n",
       "  'Have they set a date for the wedding?',\n",
       "  'Not yet.'],\n",
       " ['I hear you bought a new house in the northern suburbs.',\n",
       "  \"That's right, We bought it the same day we came on the market.\",\n",
       "  'What kind of house is it?',\n",
       "  \"It's a wonderful Spanish style.\",\n",
       "  'Oh, I love the roof tiles on Spanish style houses.',\n",
       "  \"And it's a bargaining. A house like this in river side costs double the price.\",\n",
       "  'Great, Is it a two bedroom house?',\n",
       "  \"No, It has three bedrooms and three beds, And has a living room with a twelve-foot ceiling. There's a two-car garage.\",\n",
       "  \"That's a nice area too. It'll be a good investment for you.\",\n",
       "  'Yeas, When will you buy a house?',\n",
       "  'Not untill the end of this year, You know, Just before my wedding.',\n",
       "  'Right, Congratulations.',\n",
       "  'Thank you.'],\n",
       " [\"Hi, Becky, What's up?\",\n",
       "  'Not much, Except that my mother-in-law is driving me up the wall.',\n",
       "  \"What's the problem?\",\n",
       "  \"She loves to nit-pick and criticizes everything that I do. I can never do anything right when she's around.\",\n",
       "  'For example?',\n",
       "  \"Well, Last week I invited her over to dinner. My husband and I had no problem with the food, But if you listened to her, Then it would seem like I fed her old meat and rotten vegetables. There's just nothing can please her.\",\n",
       "  \"No, I can't see that happening. I know you're a good cook and nothing like that would ever happen.\",\n",
       "  \"It's not just that. She also criticizes how we raise the kids.\",\n",
       "  \"My mother-in-law used to do the same thing to us. If it wasn't disciplining them enough, Then we were disciplining them too much. She also complained about the food we fed them, The schools we sent them too, And everything else under the sun.\",\n",
       "  'You said she used to? How did you stop her?',\n",
       "  \"We basically sat her down and told her how we felt about her constant criticizing, And how we welcomed her advice but hoped she'd let us do our things. She understood, And now everything is a lot more peaceful.\",\n",
       "  \"That sounds like a good idea. I'll have to try that.\"],\n",
       " [\"How are Zina's new programmers working out?\",\n",
       "  \"I hate to admit it, But they're good. And fast. The Filipino kid is a genius.\",\n",
       "  \"So you'll make the Stars. Com deadline, And have us up and running next week?\",\n",
       "  \"It'll be close, But we'll make it.\",\n",
       "  \"Good. After Stars. Com starts paying us, We won't need Vikam's cash anymore.\",\n",
       "  \"And if we don't need them, We won't need Zina, Either.\"]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? d\n",
      "['How', 'Ġare', 'Ġyou', '?', 'Ġd']\n",
      "['How', 'Ġare', 'Ġyou', '?', 'D', '.']\n",
      "How are you?D.\n"
     ]
    }
   ],
   "source": [
    "test_data = \"How are you? d\"\n",
    "print(test_data)\n",
    "token_list = tokenizer.tokenize(test_data.strip().replace('’', '\\'')) \n",
    "print(token_list)\n",
    "token_list = processing._process_token_list(token_list)\n",
    "print(token_list)\n",
    "new_data = tokenizer.convert_tokens_to_string(token_list)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say, Jim, How about going for a few beers after dinner?\n",
      "['Say', ',', 'ĠJim', ',', 'ĠHow', 'Ġabout', 'Ġgoing', 'Ġfor', 'Ġa', 'Ġfew', 'Ġbeers', 'Ġafter', 'Ġdinner', '?']\n",
      "[25515, 11, 5395, 11, 1374, 546, 1016, 329, 257, 1178, 16800, 706, 8073, 30]\n",
      "Say, Jim, How about going for a few beers after dinner?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for dialogue in tqdm(train):\n",
    "    for utter in dialogue:\n",
    "        tokens = tokenizer.tokenize(utter)\n",
    "        token_ids = tokenizer.encode(tokens)\n",
    "        print(utter)\n",
    "        print(tokens)\n",
    "        print(token_ids)\n",
    "        print(tokenizer.decode(token_ids))\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 32929.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from chatbot_files.data import DialoguesDataset\n",
    "train_dataset = DialoguesDataset('train', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> <speaker1> When was Rajkiya Engineering College (R. E. C.) Ambedkar Nagar established? <speaker2> Rajkiya Engineering College (R. E. C.) Ambedkar Nagar was established in 2010 by the Government of Uttar Pradesh under a special component plan.<|endoftext|>\n",
      "<bos> <speaker2> Rajkiya Engineering College (R. E. C.) Ambedkar Nagar was established in 2010 by the Government of Uttar Pradesh under a special component plan. <speaker1> What were the initial branches offered by the college? <speaker2> The college initially offered B. Tech. Programs in three branches: Information Technology (IT), Electrical Engineering (EE), And Civil Engineering (CE), With an intake of 60 students in each branch.<|endoftext|>\n",
      "<bos> <speaker1> How long did it take for the college to shift to its own campus? <speaker2> The college initially operated from the campus of Kamla Nehru Institute of Technology (K. N. I.T) in Sultanpur. It shifted to its own campus in Ambedkar Nagar in August 2012, About two years after its establishment.<|endoftext|>\n",
      "<bos> <speaker1> What is the budget allocated for the construction of the college? <speaker2> The college construction started in October 2010 with an allocated budget of 6213. 81 Lakh.<|endoftext|>\n",
      "<bos> <speaker2> The college construction started in October 2010 with an allocated budget of 6213. 81 Lakh. <speaker1> Who served as the Principal of Rajkiya Engineering College (R. E. C.) Ambedkar Nagar before January 2015? <speaker2> The Director of K. N. I.T Sultanpur served as the Principal of Rajkiya Engineering College (R. E. C.) Ambedkar Nagar until January 14, 2015.<|endoftext|>\n",
      "<bos> <speaker1> Is Rajkiya Engineering College (R. E. C.) Ambedkar Nagar affiliated with any university? <speaker2> Yes, The college is a constituent college of Uttar Pradesh Technical University, Lucknow.<|endoftext|>\n",
      "<bos> <speaker2> Yes, The college is a constituent college of Uttar Pradesh Technical University, Lucknow. <speaker1> Who is the current Director of Rajkiya Engineering College (R. E. C.) Ambedkar Nagar? <speaker2> Professor K.S. Verma is the current Director (Founder) of Rajkiya Engineering College (R. E. C.) Ambedkar Nagar. What are the central Central Facilties.<|endoftext|>\n",
      "<bos> <speaker2> Professor K.S. Verma is the current Director (Founder) of Rajkiya Engineering College (R. E. C.) Ambedkar Nagar. What are the central Central Facilties. <speaker1> Canteen, Boy's Hostel, Girl's Hostel, Atm & Banks, Library, Computer Center, Community Hall (Seminar), Play Ground. <speaker2> How to reach?<|endoftext|>\n",
      "<bos> <speaker1> When was the Department of Information Technology established at Rajkiya Engineering College (R. E. C.) Ambedkar Nagar? <speaker2> The Department of Information Technology was established in 2010, The same year the college was founded.<|endoftext|>\n",
      "<bos> <speaker1> When was the Department of Information Technology established at Rajkiya Engineering College (R. E. C.) Ambedkar Nagar? <speaker2> The Department of Information Technology was established in 2010, The same year the college was founded. <speaker1> What is the initial intake capacity of the IT department? <speaker2> The department started with an intake of 60 students. There are some other 6 seats for Lateral Entry Students.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test1 = train_dataset[0:10]\n",
    "for dar in test1[0]:\n",
    "    # print(dar)\n",
    "    # break\n",
    "    # print(len(dar))\n",
    "    print(tokenizer.decode(dar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_files.data import CorpusDataSet\n",
    "train_dataset = CorpusDataSet('train', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rajkiya Engineering College (R. E. C.) Ambedkar Nagar was established by Government of Uttar Pradesh under special component plan in year 2010, The college has started offering B. Tech Programme in three disciplines – Information Technology (IT), Electrical Engineering (EE) and Civil Engineering (CE) with intake of 60 seats in each branches from the session 2010-11.!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Rajkiya Engineering College, Ambedkar Nagar is one of the best and most reputable government engineering colleges in the state of Uttar Pradesh. Rec Ambedkar Nagar has always been excelling both on the academic and the non-academic fronts. Rajkiya Engineering College, Ambedkar Nagar is an AICTE-approved government engineering college with a well-established library and labs. Every year a large number of students from the college clear the GATE exam and get\n",
      "The work of college construction started in October 2010 with a budget of 6213. 81Lakh. The college was running in the campus of Kamla Nehru Institue of Technology, Sultanpur and has been shifted to its own campus at AmbedkarNagar in August 2012.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "The college has started offering B. Tech. Course in three disciplines- Information Technology, Electrical Engineering and Civil Engineering with intake of 60 seats in each branch from session 2010-2011.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Rajkiya Engineering College (REC), Since inception in the year 2010, Has reached new echelons in all areas of functionality showing positive growth trend in academic discourse over the years. The motive has always been to attain the global level of excellence in scientific and technical education, Fostering research, Innovation, Leadership qualities and entrepreneurial attitude, Contributing to the advancement of the society and mankind.!!!!!!!!!!!!!!!!!!!!\n",
      "We at REC consistently provide an academic and social environment that stimulates academic excellence imbibed with cross cultural adaptability, Flowering of soft skills and integration of human values & social concerns among students. In order to attain these multi facet objectives we have taken a number of steps aimed at developing the budding Engineers. This includes crafting of teaching learning modules in line with AKTU curriculum, Floating of significant number of value-added programs on advanced knowledge domains and facilitating infrastructural support for incubation &\n",
      "Rajkiya Engineering College is committed to focus on cutting edge technology, Innovations & creativity and hands on learning with an objective to convert the students from being job seekers to become job givers. In line with this philosophy, We act as a bridge between the students and various government organizations promoting entrepreneurial culture through their training programs, Easy accessibility and funding support from time to time.!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "I strongly believe that with the kind of impeccable system and support REC provides, We shall continue to create benchmarks in pursuit of achieving academic excellence and shall soon emerge as a dream destination for Engineering aspirants. \\nBest wishes!!! \\nDr. G. Nalankilli \\nDirector.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Department of information technology is the largest department of the Institute. It offers B. Tech. In Information technology. The Department is well equipped with high end computers, Latest software & IT infrastructure. All computing resources are interconnected with high speed internet. The campus wide Networking facility is also managed by the department. The Department has a well-qualified faculty and several well equipped laboratories catering to the needs of not only the IT but also students from other departments. The Department has annual intake of 60 in B.\n",
      "Civil Engineering is a traditional branch of Engineering and was amongst the founding courses when the institution was started. This is the one of the best department of the college. The department has a well-qualified faculty and technical supporting staff. All the laboratories of the department are wellequipped with modern equipment. The Department has annual intake of 60 in B. Tech. Civil Engineering.!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "test1 = train_dataset[0:10]\n",
    "for dar in test1[0]:\n",
    "    # print(dar)\n",
    "    # break\n",
    "    # print(len(dar))\n",
    "    print(tokenizer.decode(dar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_files.data import Corpus\n",
    "corpus = Corpus(tokenizer,args)\n",
    "train,valid = corpus.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 34327.43it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DialoguesDataset('train', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,type,labels = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_files.utils import PadCollate\n",
    "\n",
    "pad = PadCollate(args)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader =    DataLoader(train_dataset,\n",
    "                            collate_fn=pad,\n",
    "                            shuffle=True,\n",
    "                            batch_size=args['batch_size'],\n",
    "                            num_workers=1,\n",
    "                            pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(tensor([[50257, 50258,  8241,   318,   262,   367,  3727,   286,   262, 35262,\n",
      "           286,  6188,  8987,    30, 50259,  6187,    13, 14818, 43573,   283,\n",
      "         18383, 44202,   318,   262, 22669,  8129,   357, 40164,     8,  1222,\n",
      "           367,  3727,   286,   262, 35262,   286,  6188,  8987,    13, 50256]]), tensor([[50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "         50258, 50258, 50258, 50258, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]]), tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  6187,    13, 14818, 43573,   283,\n",
      "         18383, 44202,   318,   262, 22669,  8129,   357, 40164,     8,  1222,\n",
      "           367,  3727,   286,   262, 35262,   286,  6188,  8987,    13, 50256]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm(dataloader)):\n",
    "    input_ids, token_type_ids, labels = batch\n",
    "    print(len(batch))\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_files.data import CorpusDataSet\n",
    "args['max_length'] = args['max_len']\n",
    "corapus_train = CorpusDataSet(\"train\",args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_files.utils import PadCollateCorpus\n",
    "\n",
    "pad = PadCollateCorpus(args)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader1 =    DataLoader(corapus_train,\n",
    "                            collate_fn=pad,\n",
    "                            shuffle=True,\n",
    "                            batch_size=args['batch_size'],\n",
    "                            num_workers=1,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[36261,   286,  1321,  3037,   318,   262,  4387,  5011,   286,   262,\n",
      "          5136,    13,   632,  4394,   347,    13,  9634,    13,   554,  6188,\n",
      "          3037,    13,   383,  2732,   318,   880, 10911,   351,  1029,   886,\n",
      "          9061,    11, 26603,  3788,  1222,  7283,  6884,    13,  1439, 14492,\n",
      "          4133,   389, 40582,   351,  1029,  2866,  5230,    13,   383,  7611,\n",
      "          3094,  7311,   278,  6841,   318,   635,  5257,   416,   262,  5011,\n",
      "            13,   383,  2732,   468,   257,   880,    12, 22557, 12829,   290,\n",
      "          1811,   880, 10911, 35650, 39211,   284,   262,  2476,   286,   407,\n",
      "           691,   262,  7283,   475,   635,  2444,   422,   584, 13346,    13,\n",
      "           383,  2732,   468,  5079, 10337,   286,  3126,   287,   347,    13]]), tensor([[  286,  1321,  3037,   318,   262,  4387,  5011,   286,   262,  5136,\n",
      "            13,   632,  4394,   347,    13,  9634,    13,   554,  6188,  3037,\n",
      "            13,   383,  2732,   318,   880, 10911,   351,  1029,   886,  9061,\n",
      "            11, 26603,  3788,  1222,  7283,  6884,    13,  1439, 14492,  4133,\n",
      "           389, 40582,   351,  1029,  2866,  5230,    13,   383,  7611,  3094,\n",
      "          7311,   278,  6841,   318,   635,  5257,   416,   262,  5011,    13,\n",
      "           383,  2732,   468,   257,   880,    12, 22557, 12829,   290,  1811,\n",
      "           880, 10911, 35650, 39211,   284,   262,  2476,   286,   407,   691,\n",
      "           262,  7283,   475,   635,  2444,   422,   584, 13346,    13,   383,\n",
      "          2732,   468,  5079, 10337,   286,  3126,   287,   347,    13,     0]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, batch in enumerate(tqdm(dataloader1)):\n",
    "    # input_ids,labels = batch\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train Corpus to file...\n",
      "Saving train ids to file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 1283.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving complete!\n",
      "Saving valid Corpus to file...\n",
      "Saving valid ids to file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1065.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(tokenizer,args)\n",
    "train,validate = corpus._college_corpus()\n",
    "dataset_types = ['train', 'valid']\n",
    "datasets = [train, validate]\n",
    "for dataset_type, dataset in zip(dataset_types, datasets):\n",
    "    corpus.save(dataset_type, tokenizer, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
